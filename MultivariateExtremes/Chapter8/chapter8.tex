\documentclass[11pt]{beamer}
\usetheme{CambridgeUS}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{graphicx}

\newcommand{\E}{\operatorname{E}}
\newcommand{\Cov}{\operatorname{Cov}}
\newcommand{\argmin}{\mathop{\mathrm{argmin}}}
\newcommand{\Var}{\operatorname{Var}}
\renewcommand{\P}{\operatorname{P}}
\renewcommand{\mathbf}{\boldsymbol}
\newcommand{\norm}[1]{\left\Vert#1\right\Vert}
\newcommand{\abs}[1]{\left\vert#1\right\vert}
\newcommand{\set}[1]{\left\{#1\right\}}
\newcommand{\suit}[1]{\left(#1\right)}
\newcommand{\Real}{\mathbb R}
\newcommand{\eps}{\varepsilon}
\newcommand{\To}{\longrightarrow}
\newcommand{\A}{\mathcal{A}}
\newcommand{\td}{\stackrel{d}{\to}}
\newcommand{\tp}{\stackrel{P}{\to}}
\newcommand{\toprule}{\hline\hline}
\newcommand{\bottomrule}{\hline\hline}
\newcommand{\midrule}{\hline}

\author{de Haan and Ferreira(2006)}
\title{Estimation of the Probability of a Failsure Set}
\usecolortheme{beaver}
%\setbeamercovered{transparent} 
%\setbeamertemplate{navigation symbols}{} 
%\logo{} 

%\date{} 
%\subject{} 
\begin{document}
\begin{frame}
  \titlepage
  \begin{center}
    Chapter 8 of "Extreme value theory: An Introduction"
  
    \bigskip
    Presented by Liujun Chen.
  \end{center}
  \end{frame}


\AtBeginSection[] { 
  \begin{frame}
    \frametitle{Outline} 
    \tableofcontents[currentsection,hideothersubsections] 
  \end{frame} 
  %\addtocounter{framenumber}{-1}  %目录页不计算页码
}


%\begin{frame}
%\tableofcontents
%\end{frame}
\section{Introduction}
\begin{frame}{Introduction}
\begin{itemize}
\item In this Chapter, we we want to estimate $P((X,Y)\in C_n)$. Clearly, there is no observation (or very few) in the failure set.
\item One Example. The wave height (HmO) and still water level (SWL) have
been recorded during 828 storm events that are relevant for the Pettemer Zeewering. The failure set:
\begin{displaymath}
C=\{ (HmO,SWL): 0.3HmO + SWL > 7.6\}.
\end{displaymath}
\end{itemize}
\end{frame}


\begin{frame}{Basic Assumptions}
\begin{itemize}
\item There exist normalizing functions $a_1>0,a_2>0$ and $b_1, b_2$ real , and a distribution function $G$ with nondegenerate marginals, such that for all continuity points $(x,y)$ of $G$,
$$\lim_{t \to \infty} F^t(a_1(t)x+b_1(t),a_2(t)y+b_2(t))=G(x,y).$$
\item Moreover, we choose the functions $a_1,a_2,b_1,b_2$ such that
\begin{displaymath}
G(x,\infty)=exp(-(1+\gamma_1x)^{-1/\gamma_1}), \quad 1+\gamma_1 x>0,
\end{displaymath}
and
\begin{displaymath}
G(\infty,y)=exp(-(1+\gamma_2y)^{-1/\gamma_2}), \quad 1+\gamma_2 y>0.
\end{displaymath}
\end{itemize}
\end{frame}

\begin{frame}{Exponential Measure}
With the exponential measure defined in Section 6.1.3, 
\begin{displaymath}
\lim_{t\to \infty} P\{  \big(  (1+\gamma_1 \dfrac{X-b_1(t)}{a_1(t)})^{1/\gamma_1}, (1+\gamma_2 \dfrac{Y-b_2(t)}{a_2(t)})^{1/\gamma_2} \big) \in Q\}=v(Q),
\end{displaymath}
for all Borel sets $Q\subset \mathbb{R}_{+}^2$ with $\inf_{(x,y)\in Q} \max(x,y)>0$ and $v(\partial Q)=0$. Then for any $a>0$, we know that
\begin{displaymath}
v(aQ)=a^{-1}v(Q).
\end{displaymath}
\end{frame}

\begin{frame}{The Probability of a Failure Set}
Now, we write the probability we want to estimate in terms of the transformed variables:
\begin{equation}\tag{8.1.6}
\begin{split}
p_n: &=P((X,Y)\in C_n)\\
		&=P\{ \big(    (1+\gamma_1 \dfrac{X-b_1(t)}{a_1(t)})^{1/\gamma_1}, (1+\gamma_2 \dfrac{Y-b_2(t)}{a_2(t)})^{1/\gamma_2}            \big)\in Q_n\},
\end{split}
\end{equation}
with
\begin{displaymath}
Q_n:=\{  \big(    (1+\gamma_1 \dfrac{x-b_1(t)}{a_1(t)})^{1/\gamma_1}, (1+\gamma_2 \dfrac{y-b_2(t)}{a_2(t)})^{1/\gamma_2}            \big):(x,y)\in C_n        \}.
\end{displaymath}
We divide the set $Q_n$ by a large positive constant $c_n$ such that $Q_n/c_n$ contains a small portion of the
observations. This way we can estimate $v(Q_n/c_n)$ and hence $v(Q_n):=v(Q_n/c_n)/c_n$.
\end{frame}

\begin{frame}
  \frametitle{The Probability of a Failure Set}
Summing up, the procedure involves the following steps:
\begin{itemize}
  \item Marginal transformations
  $$
  \begin{aligned}
X_i &\to \suit{1+\gamma_1 \frac{X_i-b_1(t)}{a_1(t)}}^{1/\gamma_1}\\
  Y_i &\to \suit{1+\gamma_2 \frac{Y_i-b_2(t)}{a_2(t)}}^{1/\gamma_2}
  \end{aligned}
  $$
  in order to transform the marginal distribution approximately to a standard Pareto distribution.
  \item Use the homogeneity property of the measure $v$, in order to pull the transformed failure set to the observations.
\end{itemize}
\end{frame}


\begin{frame}{The Probability of a Failure Set}
\begin{itemize}
\item Let $k$ be an intermediate sequence, $i.e., $ $k=k(n)\to \infty, k/n \to 0,n\to \infty$.
\item Suppose the failure set $C_n$ can be written as
\begin{equation}\tag{8.1.9}
\begin{split}
C_n=\{\big( & a_1(\frac{n}{k})\frac{(c_nx)^{\gamma_1}-1}{\gamma_1}+b_1(\frac{n}{k}),\\
  & a_2(\frac{n}{k})\frac{(c_ny)^{\gamma_2}-1}{\gamma_2}+b_2(\frac{n}{k})\big ): (x,y) \in S \},
\end{split}
\end{equation}
where $c_n$ is a positive sequence and $S$ is a fixed open set of $\mathbb{R}^2$, and the marginal transformations applied to $C_n$ give the set $c_n S$ (called $Q_n$ before).
\end{itemize}
\end{frame}






\begin{frame}{The Probability of a Failure Set}
Then, for some fixed Borel set $S\subset \mathbb{R}_{+}^2$ with $\inf_{(x,y)\in Q} \max(x,y)>0$ and $v(\partial Q)=0$, we can write $(8.1.6)$ as 
\begin{displaymath}
P\{ \big(    (1+\gamma_1 \dfrac{X-b_1(\frac{n}{k})}{a_1(\frac{n}{k})})^{1/\gamma_1}, (1+\gamma_2 \dfrac{Y-b_2(\frac{n}{k})}{a_2(\frac{n}{k})})^{1/\gamma_2}            \big)\in c_n S\}.
\end{displaymath}
This is approximately equal to
\begin{displaymath}
\frac{k}{n}v(c_nS)=\frac{k}{nc_n}v(S)
\end{displaymath}
And, this leads to the estimator
\begin{displaymath}
\hat{p}_n:=\frac{k}{nc_n}\hat{v}(\hat{S}).
\end{displaymath}
Note that $S$ is not known since $\gamma_1,\gamma_2,a_1,a_2,b_1,b_2$ are not known.              
\end{frame}


\begin{frame}{Two treatment for $c_n$}
\begin{itemize}
\item Up to this point we have dealt with  $c_n$ as if it were known. This way it is to be chosen (under certain bounds) by the statistician.
\vspace{4ex}
\item An alternative way to deal with $c_n$ is to incorporate it in the problem itself, and consequently to estimate it along with the other unknown quantities.
\end{itemize}
\end{frame}


\begin{frame}{Some comments about $v(S)$}
\begin{itemize}
\item In the above discussion we assumed v(S) positive, and this will be the case considered in the next section.
\item In fact this is the case
if the random variables X and Y are not asymptotically independent or S contains (at
least part of) the axis
\begin{equation}\tag{8.1.12}
\{ (x,y):x>0 \, \text{and} \, y=0\} \lor \{ (x,y):x=0 \, \text{and} \, y>0\}.
\end{equation}
\item The case $v(S)=0$ is discussed in Section 8.3. Clearly $v(S)=0$ under asymptotic
independence and if S is contained in a set of the form $(x,\infty) \times (y,\infty)$, for some $x,y>0$.
\end{itemize}
\end{frame}

\section{Failure Set with Positive Exponent Measure}
\begin{frame}{Assumption}
 Define
\begin{displaymath}
q_n:=(1+\gamma_1 \frac{v_n-b_1(\frac{n}{k})}{a_1(\frac{n}{k})})^{1/\gamma_1},\quad r_n:=(1+\gamma_2 \frac{w_n-b_2(\frac{n}{k})}{a_2(\frac{n}{k})})^{1/\gamma_2}.
\end{displaymath}
and assume that $0<\lim_{n\to \infty} q_n/r_n<\infty$  ; this avoids the predominance of
one marginal over the other so that the problem does not become a univariate one in
the limit.
\end{frame}



\begin{frame}{First Approach: $c_n$ known}
Further Assumptions:
\begin{itemize}
\item 
\begin{displaymath}
\sqrt{k}(\hat{\gamma_i}-\gamma_i, \frac{\hat{a}_i(\frac{n}{k})}{a_i(\frac{n}{k})}-1, \dfrac{\hat{b}_i(\frac{n}{k})-b_i(\frac{n}{k})}{a_i(\frac{n}{k})})=(O_p(1),O_p(1),O_p(1)).
\end{displaymath}
\item $v(\partial S)=0$ and $v(S)>0$, and $c_n$ a sequence of positive numbers with $c_n\to \infty$.
\item Suppose $0<q_n/r_n<\infty$ (this condition imply that $q_n/r_n$ does not depend on $n$),
\begin{equation}\tag{8.2.5}
\lim_{t\to \infty} \frac{w_{\gamma_1 \land \gamma_2}(c_n)}{\sqrt{h}}=0,
\end{equation}
where
\begin{displaymath}
w_{\gamma}(t)=t^{-\gamma}\int_{1}^t s^{\gamma-1}\log s ds, t>1.
\end{displaymath}
\end{itemize}
\end{frame}


\begin{frame}{Some Remarks about the condition}
\begin{itemize}
\item The estimation of $\gamma_i,a_i(n/k), b_i(n/k)$, is known from the univariate extreme value statistics.
\item Note that the relation between k = k(n) and c n may restrict the range
of possible values of the marginal extreme value indices. For $\gamma_1\land \gamma_2<0, $ condition (8.2.5) implies
\begin{displaymath}
\lim_{t\to \infty} \dfrac{c_n^{-(\gamma_1 \land \gamma_2)}}{\sqrt{k}} =\lim_{t\to \infty} k^{-1/2-(\gamma_1 \land \gamma_2)} (\frac{k}{c_n})^{(\gamma_1 \land \gamma_2)}=0.
\end{displaymath}
For instance, if we want to allow $k/c_n=O(1)$, we must have $k^{-1/2-(\gamma_1 \land \gamma_2)}\to 0$, which is true only if $\gamma_1 \land \gamma_2>-\frac{1}{2}$.
\end{itemize}
\end{frame}


\begin{frame}{First Approach: $c_n$ known}
Then, with
\begin{displaymath}
\hat{p}_n:=\frac{1}{nc_n}\sum_{i=1}^n1_{\big \{    \big(    (1+\hat{\gamma}_1 \dfrac{X_i-\hat{b}_1(\frac{n}{k})}{\hat{a}_1(\frac{n}{k})})^{1/\hat{\gamma}_1}, (1+\hat{\gamma}_2 \dfrac{Y_i-\hat{b}_2((\frac{n}{k})}{\hat{a}_2(\frac{n}{k})})^{1/\hat{\gamma}_2}            \big) \in \hat{S}  \big \}},
\end{displaymath}
where
\begin{displaymath}
\begin{split}
\hat{S}: &=\big \{ \big (\frac{1}{c_n}(1+\hat{\gamma}_1 \dfrac{x-\hat{b}_1(\frac{n}{k})}{\hat{a}_1(\frac{n}{k})})^{1/\hat{\gamma}_1},\\
& \qquad \qquad \frac{1}{c_n}(1+\hat{\gamma}_2 \dfrac{y-\hat{b}_2(\frac{n}{k})}{\hat{a}_2(\frac{n}{k})})^{1/\hat{\gamma}_2}\big ):(x,y)\in C_n \big \},
\end{split}
\end{displaymath}
we have
\begin{displaymath}
\dfrac{\hat{p}_n}{p_n}\stackrel{p}{\to}1.
\end{displaymath}
\end{frame}

\begin{frame}{Alternative Approach: Estimate $c_n$.}
Define for some $r>0$, 
\begin{equation}\tag{8.2.9}
c_n:=\dfrac{\sqrt{q_n^2+r_n^2}}{r},
\end{equation}
where $q_n$ and $r_n$ are as in (8.2.2).  Under the same condition as Theorem 8.2.1, and with $\gamma_1 \land \gamma_2 >-1/2$, define
\begin{displaymath}
\begin{split}
\hat{q}_n &:=(1+\hat{\gamma}_1 \dfrac{v_n-\hat{b}_1(\frac{n}{k})}{\hat{a}_1(\frac{n}{k})})^{-1/\hat{\gamma}_1},\\
\hat{r}_n &:=(1+\hat{\gamma}_2 \dfrac{w_n-\hat{b}_2(\frac{n}{k})}{\hat{a}_2(\frac{n}{k})})^{-1/\hat{\gamma}_2}\\
\hat{c}_n &:=\dfrac{\sqrt{\hat{q}_n^2+\hat{r}_n^2}}{r},
\end{split}
\end{displaymath}
for some $r>0$ (to be chosen by the statistician). We can prove the consistency. And under much stronger condition, we can prove the asymptotical normality.
\end{frame}


\section{Failure Set Contained in an Upper Quadrant; Asymptotically Independent Components}


\begin{frame}{Failure Set Contained in an Upper Quadrant}
Let us start with the failure set as an upper quadrant. From (8.1.1) one gets
\begin{displaymath}
\lim_{t \to \infty} P(\frac{X-b_1(t)}{a_1(t)}> x \, \text{or}\, \frac{Y-b_2(t)}{a_2(t)}> y)=-\log G(x,y)
\end{displaymath}
and hence 
\begin{displaymath}
\begin{split}
\lim_{t \to \infty} P( &\frac{X-b_1(t)}{a_1(t)}> x \, \text{and}\, \frac{Y-b_2(t)}{a_2(t)}> y) \\
& \qquad\qquad = \log G(x,y)-\log G(x,\infty)-\log G(\infty,y),
\end{split}
\end{displaymath}
and in case of asymptotic independence the right-hand side is identically zero.
\end{frame}

\begin{frame}{Failure Set Contained in an Upper Quadrant}
More generally if $Q$ is any Borel set contained in $[u,\infty)\times [v,\infty)$, with $u,v>0$ and $v(\partial Q)=0$, under asymptotic independence of $(X, Y)$,
\begin{displaymath}
\lim_{t\to \infty} P\{  \big(  (1+\gamma_1 \dfrac{X-b_1(t)}{a_1(t)})^{1/\gamma_1}, (1+\gamma_2 \dfrac{Y-b_2(t)}{a_2(t)})^{1/\gamma_2} \big) \in Q\}=0,
\end{displaymath}
This gives too little information on the probability of the set $Q$.we propose the following refinement of (8.1.4), which will lead to a new limit measure $v$: for $x,y>0$, 
\begin{displaymath}
\lim_{t\to \infty}r(t) P\big \{ (1+\gamma_1 \dfrac{X-b_1(t)}{a_1(t)})^{1/\gamma_1}>x ,\, \text{and}\,    (1+\gamma_2 \dfrac{Y-b_2(t)}{a_2(t)})^{1/\gamma_2}>y   \big  \}
\end{displaymath}
exists, and it is positive and finite.
\end{frame}


\begin{frame}{Failure Set Contained in an Upper Quadrant}
Then, we can redifine the exponential measure $v$ as follows: for any Borel set $Q$ in $\mathbb{R}_{+}^2$ with $\inf_{(x,y)\in Q} \max(x,y)>0$ and $v(\partial Q)=0$, let
\begin{displaymath}
\begin{split}
&v(Q)\\
  &:=\lim_{t\to \infty} P\{  \big(  (1+\gamma_1 \dfrac{X-b_1(t)}{a_1(t)})^{1/\gamma_1}, (1+\gamma_2 \dfrac{Y-b_2(t)}{a_2(t)})^{1/\gamma_2} \big) \in Q\}.
\end{split}
\end{displaymath}
Moreover, it follows that the function r is regularly varying with index greater than
or equal to 1. Also, in the proof of Theorem 6.1.9, it follows that
\begin{displaymath}
v(aQ)=a^{-1/\eta}v(Q).
\end{displaymath}
\end{frame}

\begin{frame}{Failure Set Contained in an Upper Quadrant}
We are now ready to proceed with the estimation of p n , which closely follows the
reasoning developed in the previous section. Using again (8.1.8),
\begin{displaymath}
\begin{split}
p_n&=P((X,Y)\in C_n)\\
 &=P\big \{ \big(    (1+\gamma_1 \dfrac{X-b_1(\frac{n}{k})}{a_1(\frac{n}{k})})^{1/\gamma_1}, (1+\gamma_2 \dfrac{Y-b_2(\frac{n}{k})}{a_2(\frac{n}{k})})^{1/\gamma_2}            \big)\in c_n S\}.
\end{split}
\end{displaymath}
which is approximately equal to
\begin{displaymath}
\dfrac{v(c_nS)}{r(\frac{n}{k})}=\dfrac{v(S)}{c_n^{1/\eta}r(\frac{n}{k})}.
\end{displaymath}
The estimation procedure is the same as before. And the consistency can be proved.
\end{frame}


























































































\end{document}
