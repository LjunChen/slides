\documentclass[11pt]{beamer}
\usetheme{Boadilla}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{MnSymbol}
\author{Engelke and Hitz}
\newcommand{\bx}{\boldsymbol{x}}
\newcommand{\bX}{\boldsymbol{X}}
\newcommand{\bY}{\boldsymbol{Y}}
\newcommand{\by}{\boldsymbol{y}}
\newcommand{\bZ}{\boldsymbol{Z}}
\newcommand{\bz}{\boldsymbol{z}}
\title{Graphical Models for Extremes}
%\setbeamercovered{transparent} 
%\setbeamertemplate{navigation symbols}{} 
%\logo{} 
%\institute{} 
%\date{} 
%\subject{} 
\begin{document}

\begin{frame}
\titlepage
\end{frame}

%\begin{frame}
%\tableofcontents
%\end{frame}

\begin{frame}{Introduction}
Extreme Value theory in multivariate case. Assume $\bX\in \mathbb{R}^d$.
\begin{itemize}
\item Max-stable distributions arise as limits of normalized maxima of independent copies of $\bX$.
\item Multivariate Pareto distributions describe the random vector
$\bX$ conditioned on the event that at least one component exceeds a high threshold.
\end{itemize}
\end{frame}

\begin{frame}{Sparse Multivariate Models}
\begin{itemize}
\item Sparse multivariate
models require the notion of conditional independence.
\item The problem is how to define the conditional independence for tail dependence.
\item If $(Z_1,Z_2,Z_3)$ is a max-stable random vector with positive continuous density, then the conditional independence of $Z_{1} \upmodels Z_{3} \mid Z_{2}$ already implies the independence $Z_{1} \upmodels Z_{3}$.
\item Meaningful conditional independence structures can thus only be obtained
for max-stable distributions with discrete spectral measure.

\end{itemize}
\end{frame}

\begin{frame}{Graphical Models}
We now consider the Multivariate Pareto distribution $\bY=(Y_1,\dots,Y_d)$.

\vspace{3ex}

For an undirected graph $\mathcal{G}=(V, E)$ with nodes $V=\{1,2,\dots,d\}$ and edge set $E$, we say that $\bY$ is an extremal graphical model if it satisfies the pairwise Markov property
$$
\bY_{i} \perp_{\mathrm{e}} \bY_{j} \mid \bY_{\backslash\{i, j\}}, \quad(i, j) \notin E,
$$
where we use $\perp_{\mathrm{e}}$ to stress that it is designed for extremes. (And we will define this later.)

\vspace{3ex}

The main advantage of conditional independence and graphical models is that they imply a
simple probabilistic structure and possibly sparse patterns in multivariate random vectors.
\end{frame}

\begin{frame}{Multivariate extreme value theory}\
\begin{itemize}
\item Let $\bX_{i}=\left(X_{i 1}, \ldots, X_{i d}\right), i=1, \ldots, n$ be independent copies of $\bX$ and denote the componentwise maximum by $\mathbf{M}_{n}=\left(M_{1 n}, \ldots, M_{d n}\right)=\left(\max _{i=1}^{n} X_{i 1}, \ldots, \max _{i=1}^{n} X_{i d}\right)$.
\item Assume there are sequences of normalizing constants $b_{jn}\in \mathbb{R},a_{jn}>0$, such that
$$
\lim _{n \rightarrow \infty} \mathbb{P}\left(\frac{M_{j n}-b_{j n}}{a_{j n}} \leqslant x\right)=G_{j}(x)=\exp \left\{-\left(1+\xi_{j} x\right)_{+}^{-1 / \xi_{j}}\right\}, \quad x \in \mathbb{R}.
$$
\end{itemize}
\end{frame}


\begin{frame}{Multivariate extreme value theory}
Assume
$$
\lim _{n \rightarrow \infty} \mathbb{P}\left(\max _{i=1, \ldots, n} X_{i 1} \leqslant n z_{1}, \ldots, \max _{i=1, \ldots, n} X_{i d} \leqslant n z_{d}\right)=\mathbb{P}(\bZ \leqslant \bz)
$$
In this case, $\bZ$ is max-stable with standard Fr\'echet marginals $\mathbb{P}(Z_j\le z)=\exp(-1/z)$ and we may write
$$
\mathbb{P}(\bz \leqslant \bz)=\exp \{-\Lambda(\bz)\}, \quad \bz \in \mathcal{E}
$$
where the exponent measure $\Lambda$ is a Radon measure on the cone $\mathcal{E}=[0, \infty)^{d} \backslash\{\boldsymbol{0}\}$ and $\Lambda(\bz)$ is shorthand for $\Lambda(\mathcal{E} \backslash[\mathbf{0}, \bz])$.
\end{frame}


\begin{frame}{Multivariate extreme value theory}
If $\Lambda$ is absolutely continuous with respect to Lebesgue measure on $\mathcal{E}$,  its Radonâ€“Nikodym derivative, denoted by $\lambda$ has the following properties
\begin{itemize}
\item homogeneity of order $-(d+1)$, i.e. $\lambda(t\by)=t^{-(d+1)}\lambda(\by)$.
\item normalized marginals, i.e. for any $i=1,\dots,d$,
$$
\int_{\mathbf{y} \in \mathcal{E}: y_{i}>1} \lambda(\by) \mathrm{d} \by=1
$$
\end{itemize}
\end{frame}

\begin{frame}{Multivariate extreme value theory}
Another perspective on multivariate extremes is through threshold exceedances
$$
\lim _{u \rightarrow \infty} u\{1-\mathbb{P}(\bX \leqslant u \bz)\}=\Lambda(\bz), \quad \bz \in \mathcal{E}
$$
Consequently, the multivariate distribution of the threshold exceedances of $\bX$ satisfies
$$
\mathbb{P}(\mathbf{Y} \leqslant \bz)=\lim _{u \rightarrow \infty} \mathbb{P}\left(\frac{\bX}{u} \leqslant \bz \mid\|\bX\|_{\infty}>u\right)=\frac{\Lambda(\bz \wedge \mathbf{1})-\Lambda(\bz)}{\Lambda(\mathbf{1})}.
$$
The distribution of the limiting random vector $\bY$ is called amultivariate Pareto distribution.

\vspace{3ex}

It is defined through the exponent measure $\Lambda$ of the max-stable
distribution $\bZ$, with support on the $L$-shaped space $\mathcal{L}=\left\{\mathbf{x} \in \mathcal{E}:\|\bx\|_{\infty}>1\right\}$.
\end{frame}

\end{document}